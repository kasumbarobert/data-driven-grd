{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e3fbf7-90dd-448b-9ad1-080ecefc3440",
   "metadata": {},
   "source": [
    "# GRD model\n",
    "- initial grid\n",
    "- optimal paths to goals\n",
    "- actions (positions that are visited on any of the paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a04e2ba-7383-42b5-b32e-9490e2e481bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from utils import *\n",
    "from baseline_utils import *\n",
    "from collections import deque\n",
    "import time\n",
    "import seaborn as sns\n",
    "import multiprocessing\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "141c2990-5d7e-4a38-bb9e-ab3c79d07879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_search_greedy_pred_wcd(root_grd_model, prediction_model):\n",
    "    # If you have multiple GPUs, replace '0' with the appropriate GPU index\n",
    "    device = 'cpu'\n",
    "\n",
    "    # Set the device\n",
    "    # torch.cuda.set_device(device)\n",
    "\n",
    "    # Move the model and any data to the correct device\n",
    "    root_grd_model\n",
    "    prediction_model.to()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Make sure any data passed to the model is on the correct device\n",
    "    final_grd = greedy_search_predicted_wcd(root_grd_model, model=prediction_model)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_taken = end_time - start_time\n",
    "    wcd_diff = root_grd_model.get_wcd() - final_grd.get_wcd() if final_grd is not None else None\n",
    "\n",
    "    # Move the result to CPU before putting it in the output queue\n",
    "    return final_grd if final_grd is not None else None, time_taken, wcd_diff\n",
    "\n",
    "\n",
    "def run_greedy_search_with_timeout(timeout, root_grd_model, prediction_model): # this is a special implementation due to issues with multithreading and CUDA\n",
    "    try:\n",
    "        # Run the function with a specified timeout\n",
    "        result = func_timeout(timeout, run_search_greedy_pred_wcd, args=(root_grd_model, prediction_model))\n",
    "        return result\n",
    "    except FunctionTimedOut:\n",
    "        # Handle the timeout case\n",
    "        print(f\"The function exceeded the {timeout} second timeout.\")\n",
    "        return None, 20, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "586c99a7-d473-422d-a583-2ad681fe0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_timeout import func_timeout, FunctionTimedOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "083f3e2e-c389-4aea-b27e-d01309d051fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c4753a-cfdc-4209-8560-ca491dd24370",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 0.21318340301513672\n",
      "0 100 0.46686458587646484\n",
      "4 200 2.503377914428711\n",
      "0 300 0.31859779357910156\n",
      "2 400 1.047966718673706\n",
      "0 500 0.47065210342407227\n",
      "0 600 0.7762866020202637\n",
      "0 700 0.5423309803009033\n",
      "0 800 0.29735612869262695\n",
      "0 900 0.2990453243255615\n",
      "0 1000 0.5877892971038818\n",
      "0 1100 0.5960292816162109\n",
      "0 1200 0.5536904335021973\n",
      "The function exceeded the 20 second timeout.\n",
      "4 1300 1.2484180927276611\n",
      "0 1400 0.4576265811920166\n",
      "3 1500 1.733069896697998\n",
      "2 1600 0.9920616149902344\n",
      "4 1700 1.2628562450408936\n",
      "2 1800 1.9170525074005127\n",
      "0 1900 0.4502692222595215\n",
      "3 2000 0.857572078704834\n",
      "0 2100 0.5700702667236328\n",
      "0 2200 0.16923904418945312\n",
      "0 2300 0.5412843227386475\n",
      "4 2400 1.7321584224700928\n",
      "0 2500 0.4509909152984619\n",
      "0 2600 0.9823765754699707\n",
      "4 2700 1.3864836692810059\n",
      "0 2800 0.25606703758239746\n",
      "0 2900 0.1614539623260498\n",
      "0 3000 0.7868077754974365\n",
      "1 3100 1.0102884769439697\n",
      "0 3200 1.0771763324737549\n",
      "0 3300 0.41605520248413086\n",
      "5 3400 1.106342077255249\n",
      "0 3500 0.4065062999725342\n",
      "0 3600 0.28778600692749023\n",
      "0 3700 0.1495976448059082\n",
      "1 3800 1.2943074703216553\n",
      "The function exceeded the 20 second timeout.\n",
      "0 3900 0.4423816204071045\n",
      "7 4000 0.6787645816802979\n",
      "1 4100 0.9377701282501221\n",
      "0 4200 0.4819483757019043\n",
      "0 4300 0.42290711402893066\n",
      "0 4400 0.6635892391204834\n",
      "0 4500 0.09828901290893555\n",
      "0 4600 0.5765292644500732\n",
      "0 4700 0.5756337642669678\n",
      "0 4800 0.45095300674438477\n",
      "0 4900 0.28148341178894043\n",
      "0 5000 0.526928186416626\n",
      "3 5100 1.432755947113037\n",
      "1 5200 0.9918570518493652\n",
      "0 5300 0.42997050285339355\n",
      "0 5400 0.7473478317260742\n",
      "4 5500 1.4302685260772705\n",
      "0 5600 0.16970300674438477\n",
      "5 5700 0.6818363666534424\n",
      "0 5800 0.4360635280609131\n",
      "0 5900 0.004992485046386719\n",
      "3 6000 0.6933908462524414\n",
      "0 6100 0.5751309394836426\n",
      "0 6200 0.5788092613220215\n",
      "0 6300 0.8227486610412598\n",
      "0 6400 0.4315462112426758\n",
      "0 6500 0.2468111515045166\n",
      "0 6600 0.2983527183532715\n",
      "1 6700 0.8460314273834229\n",
      "5 6800 0.9781501293182373\n",
      "1 6900 0.6229350566864014\n",
      "0 7000 0.5713479518890381\n",
      "0 7100 0.41880035400390625\n",
      "The function exceeded the 20 second timeout.\n",
      "1 7200 1.1824321746826172\n",
      "4 7300 1.7061517238616943\n",
      "4 7400 1.4172477722167969\n",
      "0 7500 0.5094983577728271\n",
      "0 7600 0.5380752086639404\n",
      "0 7700 0.4027371406555176\n",
      "0 7800 0.26151013374328613\n",
      "0 7900 0.004202127456665039\n",
      "3 8000 1.4926860332489014\n",
      "0 8100 0.2783644199371338\n",
      "3 8200 0.6056172847747803\n",
      "0 8300 0.461317777633667\n",
      "1 8400 1.0413219928741455\n"
     ]
    }
   ],
   "source": [
    "with open(f\"../data/dataset_6.pkl\", \"rb\") as f:\n",
    "        loaded_dataset = pickle.load(f)\n",
    "grid_size =6\n",
    "device =\"cuda:0\"\n",
    "experiment_label = \"ALL_MODS_GREEDY_PRED_WCD\" #\"baseline\" \n",
    "\n",
    "model_label = f\"../models/wcd_nn_model.pt\"\n",
    "device =\"cuda:0\"\n",
    "model = torch.load(model_label)\n",
    "prediction_model = model.cpu().eval()\n",
    "\n",
    "times = []\n",
    "wcd_change = []\n",
    "\n",
    "\n",
    "for i in range(0, len(loaded_dataset),10):\n",
    "    x, y = loaded_dataset[i]  # Get a specific data sample\n",
    "    x = x.unsqueeze(0).float().cuda()\n",
    "    grid = decode_grid_design(x[0].cpu(), return_map=True)\n",
    "    grid_size, goal_positions, blocked_positions, start_pos,unblocked_positions = decode_grid_design(x[0].cpu())\n",
    "\n",
    "    is_valid, cost_to_goals = is_design_valid(grid_size, goal_positions, blocked_positions, start_pos)\n",
    "    if not is_valid:\n",
    "        print(\"INVALID Original evironment\")\n",
    "\n",
    "    wcd,paths,wcd_paths = compute_wcd_single_env(grid_size, goal_positions, blocked_positions, start_pos, vis_paths = False, return_paths = True)\n",
    "\n",
    "    root_grd_model = GRDModel( grid_size = grid_size, start_pos = start_pos, goal_positions = goal_positions,\n",
    "                              blocked_positions = blocked_positions, unblocked_positions = unblocked_positions,\n",
    "                             init_goal_costs = cost_to_goals, compute_wcd = False)\n",
    "    \n",
    "\n",
    "    final_grd, time_taken, wcd_diff = run_with_timeout(20, root_grd_model, prediction_model)\n",
    "    times.append(time_taken)\n",
    "    wcd_change.append(wcd_diff)\n",
    "    init_grid = grid.copy()\n",
    "    \n",
    "    if not final_grd is None:\n",
    "        final_grid = init_grid.copy()\n",
    "        for b in final_grd.blocked_positions:\n",
    "            final_grid[b[0],b[1]] =\"X\"\n",
    "        for b in final_grd.unblocked_positions:\n",
    "            final_grid[b[0],b[1]] =\" \"\n",
    "    else:\n",
    "        final_grid = init_grid\n",
    "        final_grd = root_grd_model\n",
    "    x_final = encode_from_grid_to_x(grid)\n",
    "\n",
    "    # update_or_create_dataset(f\"initial_envs_{grid_size}_{experiment_label}.pkl\", [x], [y.item()]) # store the initial environments\n",
    "    # update_or_create_dataset(f\"final_envs_{grid_size}_{experiment_label}.pkl\", [x_final], [final_grd.get_wcd()]) # store the final environments\n",
    "    # create_or_update_list_file(f\"data/times_{experiment_label}.csv\",times)\n",
    "    \n",
    "\n",
    "    # Process your results here\n",
    "    # print(f\"Time taken: {time_taken} seconds\")\n",
    "    if final_grd:\n",
    "        # Additional processing if final_grd is not None\n",
    "        pass\n",
    "\n",
    "    if i % 100 ==0:\n",
    "        print(final_grd.get_wcd(),i, times[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fb2681-6bfb-4011-8c7e-a22549c6b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_search(root_grd_model, output,prediction_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739ec5aa-95a1-4ae9-9ecc-a1e5e738a45d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c08f4-5d40-446c-af87-71ebcec0786f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
